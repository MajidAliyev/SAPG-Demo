# Self-Auditing Prompt Generator (SAPG)

> **Transform simple prompts into auditable, error-free outputs through systematic self-correction.**

The SAPG implements a practical **Draft â†’ Critique â†’ Revision** cycle to address the fundamental flaw that AI agents often fail due to systemic, non-auditable errors.

## ğŸ“– For Beginners

**New to programming?** Check out [QUICKSTART.md](QUICKSTART.md) for step-by-step installation instructions!

## ğŸ¯ What It Solves

**The Core Gap**: AI agents often produce outputs with logical flaws, infinite loops, missing exception handling, and compliance risks that go undetected.

**The Solution**: Instead of running an LLM prompt once, the SAPG uses a three-phase self-correction cycle:

1. **Draft**: An agent generates a complex execution plan
2. **Critique**: A secondary agent systematically checks for errors, infinite loops, missing exception handling, and compliance risks
3. **Revision**: The first agent uses the critique to generate a corrected, auditable final output

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SELF-AUDITING PROTOCOL (SAP)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Phase 1: DRAFT AGENT                           â”‚
â”‚  â†’ Generates initial solution                   â”‚
â”‚                                                  â”‚
â”‚  Phase 2: CRITIQUE AGENT                        â”‚
â”‚  â†’ Audits for:                                  â”‚
â”‚     - Logical flaws                             â”‚
â”‚     - Infinite loops                            â”‚
â”‚     - Missing exception handling                â”‚
â”‚     - Compliance risks                          â”‚
â”‚                                                  â”‚
â”‚  Phase 3: REVISION AGENT                        â”‚
â”‚  â†’ Incorporates feedback                        â”‚
â”‚     â†’ Produces corrected output                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip
- Git (optional, for cloning)

### Installation

1. **Clone this repository from GitHub**

   ```bash
   git clone https://github.com/yourusername/SACC.git
   cd SACC
   ```

   Or download as ZIP and extract it.

   **Note**: Replace `yourusername` with your actual GitHub username!

2. **Install Python dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Install Ollama (or use cloud APIs):**

   **Option A: Ollama (Local - Recommended for Free Use)**

   ```bash
   # Install Ollama from https://ollama.ai
   # Then pull a model:
   ollama pull llama2
   # or
   ollama pull mistral
   ```

   **Option B: OpenAI API**

   ```bash
   pip install langchain-openai
   ```

   **Option C: Anthropic API**

   ```bash
   pip install langchain-anthropic
   ```

4. **Configure environment (for API providers, optional)**

   Create a `.env` file in the project folder:

   ```bash
   # For OpenAI
   OPENAI_API_KEY=your_api_key_here

   # OR for Anthropic
   ANTHROPIC_API_KEY=your_api_key_here
   ```

5. **Run the application**

   ```bash
   streamlit run app.py
   ```

6. **Open your browser**

   The app will automatically open at `http://localhost:8501`

## ğŸ’» Usage

1. **Configure LLM Provider**

   - Select your provider (Ollama, OpenAI, or Anthropic) in the sidebar
   - Choose a model (e.g., `llama2`, `gpt-3.5-turbo`, `claude-3-sonnet`)

2. **Enter Your Request**

   - Type or select an example request (e.g., "Create a secure authentication system")
   - Be specific about what you need generated

3. **Execute Self-Audit**

   - Click "Execute Self-Audit" to run the Draft â†’ Critique â†’ Revision cycle
   - Watch as the system generates, critiques, and revises the output

4. **Review Results**
   - **Final Output**: The corrected, production-ready result
   - **Draft**: See the initial output
   - **Critique**: View the systematic audit findings
   - **Revision**: See how the feedback was incorporated

## ğŸ“‹ Example Use Cases

- **Code Generation**: Generate Python scripts with proper error handling
- **ETL Pipelines**: Design data pipelines with validation and compliance checks
- **Security Systems**: Build authentication systems with rate limiting and security best practices
- **Data Analysis**: Create analysis scripts with privacy safeguards
- **Business Plans**: Generate multi-step plans with risk assessment

## ğŸ› ï¸ Technology Stack

- **Python**: Core language
- **Streamlit**: Web UI framework
- **LangChain**: Agent orchestration
- **Ollama**: Local LLM server (or OpenAI/Anthropic APIs)
- **LangChain Community**: Provider integrations

## ğŸ“ Project Structure

```
SACC/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ agents.py           # Agent definitions (Draft, Critique, Revision)
â”œâ”€â”€ protocol.py         # Self-Auditing Protocol template
â”œâ”€â”€ llm_factory.py     # LLM provider factory
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ pytest.ini         # Pytest configuration
â”œâ”€â”€ README.md          # This file
â”œâ”€â”€ tests/             # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_llm_factory.py
â”‚   â”œâ”€â”€ test_protocol.py
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â””â”€â”€ conftest.py
â””â”€â”€ .env               # Environment variables (create this)
```

## ğŸ“ How It Works

### The Self-Auditing Protocol

The SAPG implements a formal protocol that defines:

1. **Agent Roles**: Distinct agents for Draft, Critique, and Revision
2. **Systematic Auditing**: Checklist-based review (logical flaws, loops, security, etc.)
3. **Recursive Nature**: The protocol applies to itself (meta-critical thinking)
4. **Bounded Self-Correction**: Prevents "hallucination cascades"

### The Intelligent Gap

Traditional AI tools run a prompt once and return the output. The SAPG adds an intelligent layer:

- **Single-shot systems** fail due to undetected errors
- **Self-auditing systems** catch errors before delivery
- This creates **provable safety** through systematic verification

## ğŸ¯ Hiring Leverage

This project demonstrates:

- **Agent-native design**: Systems built specifically for LLM agents
- **Provable safety**: Formal methods for AI reliability
- **Recursive architectures**: Self-correcting AI systems
- **Production AI**: Moving beyond single-shot "copilot" responses

## ğŸ”§ Customization

### Add Custom Audit Criteria

Edit `protocol.py` to add domain-specific audit checks:

```python
CUSTOM_CRITERIA = """
â–¡ DATABASE: Proper connection pooling and transaction handling
â–¡ API: Rate limiting and authentication checks
â–¡ UI: Accessibility and cross-browser compatibility
"""
```

### Use Different LLMs

Modify `llm_factory.py` to add support for additional providers (Cohere, HuggingFace, etc.)

### Extend the Cycle

Add more phases (e.g., "Validation" phase after Revision) by extending the orchestrator in `agents.py`

## ğŸ“ License

Open source - MIT License (or as specified)

## ğŸ§ª Testing

For detailed testing instructions, see [TESTING.md](TESTING.md).

**Quick start:**

```bash
# Install test dependencies
pip install pytest pytest-cov pytest-mock

# Run all tests
pytest

# Run with coverage report
pytest --cov=. --cov-report=html

# View coverage: open htmlcov/index.html
```

See TESTING.md for comprehensive testing guide.

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Areas for improvement:**

- Additional LLM providers
- Custom audit criteria templates
- Batch processing for multiple requests
- Export functionality (PDF, Markdown, etc.)

## ğŸŒ Deployment

Want to share this with others online? Deploy to:

- **Streamlit Cloud**: https://streamlit.io/cloud
- **Heroku**: Use a Procfile and deploy via Heroku CLI
- **AWS/Azure/GCP**: Deploy as a containerized app

See the deployment guides in the `docs/` folder (create as needed).

## ğŸ™ Credits

Inspired by research on AI failure modes and recursive self-correction systems.
